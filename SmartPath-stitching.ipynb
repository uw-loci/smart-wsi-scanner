{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmartPath: Intelligent Multimodal Acquisition for Histopathological Whole Slide Scanning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Instructions:  \n",
    "How to run a cell (section)?\n",
    "Click blank space in front of the '...' below each section and hit Shift+Return, or click the \"run the selected cells and advance\" botton in the top menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. System configuration\n",
    "Note: wait for \"System configured!\" Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System configured!\n"
     ]
    }
   ],
   "source": [
    "import os, glob, shutil, sys, copy, time, json, copy, subprocess, math, warnings\n",
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "from pycromanager import Acquisition, Bridge, Dataset, multi_d_acquisition_events\n",
    "from skimage import io, img_as_ubyte, img_as_float, img_as_uint, color, transform, exposure\n",
    "from skimage.filters import threshold_mean, sobel\n",
    "from skimage.measure import shannon_entropy\n",
    "from skimage.util import view_as_windows, crop\n",
    "import imagej\n",
    "import json\n",
    "import threading\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from scipy.stats import norm\n",
    "import scipy as sp\n",
    "from shapely.geometry import mapping, shape\n",
    "from tkinter import filedialog\n",
    "from IPython.display import Audio \n",
    "\n",
    "from acquisitions import *\n",
    "# from acquisitions_with_commentedout_DCC_line101 import *\n",
    "from image_utils import *\n",
    "from enhancer import Enhancer\n",
    "from predictor import Predictor\n",
    "\n",
    "os.environ['_JAVA_OPTIONS']=\"-Xmx12g\"\n",
    "warnings.filterwarnings('ignore')\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def config_sys(config):\n",
    "    if config[\"exposure-level\"]==\"low\":\n",
    "        config[\"lsm-scan-rate\"] = '500000.0000'\n",
    "        config[\"lsm-pc-power\"] = 0.3\n",
    "        config[\"lsm-pmt-gain\"] = 0.35\n",
    "    if config[\"exposure-level\"]==\"mid\":\n",
    "        config[\"lsm-scan-rate\"] = '400000.0000'\n",
    "        config[\"lsm-pc-power\"] = 0.4\n",
    "        config[\"lsm-pmt-gain\"] = 0.4\n",
    "    if config[\"exposure-level\"]==\"high\":\n",
    "        config[\"lsm-scan-rate\"] = '250000.0000'\n",
    "        config[\"lsm-pc-power\"] = 0.425\n",
    "        config[\"lsm-pmt-gain\"] = 0.425\n",
    "    if config[\"exposure-level\"]==\"extreme\":\n",
    "        config[\"lsm-scan-rate\"] = '200000.0000'\n",
    "        config[\"lsm-pc-power\"] = 0.45\n",
    "        config[\"lsm-pmt-gain\"] = 0.45\n",
    "    config[\"pixel-size-shg\"] = config[\"pixel-size-shg-base\"] * 256 / config[\"lsm-resolution\"]\n",
    "    if config[\"enhancement-type\"] is not None:\n",
    "        config[\"enhancer\"] = Enhancer(config)\n",
    "    if config[\"classifier\"] is not None:\n",
    "        config[\"predictor\"] = Predictor(config)\n",
    "    return config\n",
    "\n",
    "def distance(pos, support_points):\n",
    "    pos = np.array(pos)\n",
    "    support_points = np.array(support_points)\n",
    "    distances = np.sqrt((pos - support_points)[:, 0]**2 + (pos - support_points)[:, 1]**2)\n",
    "    idx = np.argmin(distances, axis=0)\n",
    "    return idx, distances[idx]\n",
    "\n",
    "def whole_slide_scan(config, core=None, save_path=None, acq_name=None, position_list=None, mag='4x', mda=False, z_stack=False, z_center=None, \n",
    "                     sample_depth=20, z_step=4, estimate_background=False, background_image=None, focus_dive=False):\n",
    "    if mda == True:\n",
    "        if position_list.shape[1] == 3:\n",
    "            if z_stack:\n",
    "                with Acquisition(save_path, acq_name, lsm_process_fn(config)) as acq:\n",
    "                    events = multi_d_acquisition_events(xyz_positions=position_list.reshape(-1, 3), z_start=-int(sample_depth/2), z_end=int(sample_depth/2), z_step=z_step)\n",
    "                    acq.acquire(events)      \n",
    "            else:\n",
    "                with Acquisition(save_path, acq_name) as acq:\n",
    "                    events = multi_d_acquisition_events(xyz_positions=position_list.reshape(-1, 3))\n",
    "                    acq.acquire(events)\n",
    "        else:\n",
    "            if z_center is None:\n",
    "                z_center = config[\"Z-stage-laser\"]\n",
    "            if z_stack:\n",
    "                with Acquisition(save_path, acq_name) as acq:\n",
    "                    events = multi_d_acquisition_events(xy_positions=position_list.reshape(-1, 2), z_start=-int(sample_depth/2) + z_center, z_end=int(sample_depth/2) + z_center, z_step=z_step)\n",
    "                    acq.acquire(events)\n",
    "            else:\n",
    "                with Acquisition(save_path, acq_name) as acq:\n",
    "                    events = multi_d_acquisition_events(xy_positions=position_list.reshape(-1, 2))\n",
    "                    acq.acquire(events)\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "        plt.axis(\"off\")\n",
    "        show = plt.imshow(np.zeros((config[\"camera-resolution\"][1], config[\"camera-resolution\"][0])))\n",
    "        acq_id = len(glob.glob(os.path.join(save_path, acq_name+\"*\")))\n",
    "        acq_path = os.path.join(save_path, acq_name+\"_{}\".format(acq_id+1))\n",
    "        os.makedirs(acq_path, exist_ok=True)\n",
    "        bg_flag = False\n",
    "        if estimate_background:\n",
    "            bg_stack = []\n",
    "        if background_image is not None and not estimate_background:\n",
    "            bg_img = white_balance(copy.deepcopy(background_image), copy.deepcopy(background_image))\n",
    "            \n",
    "        if mag == '4x':\n",
    "            pos_z = config[\"Z-stage-4x\"]\n",
    "        elif mag == '20x':\n",
    "            pos_z = config[\"Z-stage-20x\"] \n",
    "        support_points = [(99999999, 99999999)] # dummy support point\n",
    "        support_focus = [pos_z]\n",
    "        \n",
    "        if position_list.shape[1] == 3:\n",
    "            tile_count = 0\n",
    "            z_positions=np.ones(position_list.shape[0]) * core.get_position()\n",
    "            core.set_focus_device(config[\"focus-device\"])\n",
    "            autofocus_count = 0\n",
    "            for pos in range(position_list.shape[0]):\n",
    "                z_pos = position_list[pos, 2]\n",
    "                x_pos = position_list[pos, 0]\n",
    "                y_pos = position_list[pos, 1]\n",
    "                x_pos, y_pos, z_pos = limit_stage(config, (x_pos, y_pos, z_pos)) #, (config[\"hard-limit-x\"][0], config[\"hard-limit-x\"][1], config[\"Z-stage-4x\"]))\n",
    "                core.set_position(z_pos)\n",
    "                core.set_xy_position(x_pos, y_pos)\n",
    "                xy_device = core.get_xy_stage_device()\n",
    "                z_device = core.get_focus_device()\n",
    "                core.wait_for_device(xy_device)\n",
    "                core.wait_for_device(z_device)\n",
    "                \n",
    "                if focus_dive and mag=='4x':\n",
    "                    support_distance = config[\"pixel-size-bf-4x\"] * config[\"camera-resolution\"][1] * config[\"autofocus-speed\"]\n",
    "                    idx, min_distance = distance((x_pos, y_pos), support_points)\n",
    "                    if min_distance <= support_distance:\n",
    "                        pos_z = support_focus[idx]\n",
    "                        pos_z = limit_stage(config, (pos_z,), (config[\"Z-stage-4x\"],))\n",
    "                        core.set_position(pos_z)\n",
    "                        core.wait_for_device(z_device)\n",
    "                        pixels = snap_image(core, rgb=True, flip_channel=True)\n",
    "                        bg_flag = is_background(pixels, t=0.35, tt=0.35)\n",
    "                    else:\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='4x', rgb=True, search_range=100, steps=3, snap=True, preset=z_pos) # snap at top but return center z\n",
    "                        if bg_flag:\n",
    "                            if len(support_points)>=2:\n",
    "                                core.set_position(pos_z)\n",
    "                            else:\n",
    "                                pos_z = z_pos\n",
    "                            core.wait_for_device(z_device)\n",
    "                            pixels = snap_image(core, rgb=True, flip_channel=True)\n",
    "                        else:\n",
    "                            support_points.append((x_pos, y_pos))\n",
    "                            support_focus.append(pos_z)\n",
    "                    z_positions[pos] = pos_z\n",
    "                           \n",
    "                if focus_dive and mag=='20x':\n",
    "                    support_distance = config[\"pixel-size-bf-20x\"] * config[\"camera-resolution\"][1] * config[\"autofocus-speed\"]\n",
    "                    idx, min_distance = distance((x_pos, y_pos), support_points)\n",
    "                    if min_distance <= support_distance:\n",
    "                        pos_z = support_focus[idx]\n",
    "                        pos_z = limit_stage(config, (pos_z,), (config[\"Z-stage-20x\"],))\n",
    "                        core.set_position(pos_z)\n",
    "                        core.wait_for_device(z_device)\n",
    "                        pixels = snap_image(core, rgb=True, flip_channel=True)\n",
    "                        bg_flag = is_background(pixels, t=0.35, tt=0.35)\n",
    "                    else:\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='20x', rgb=True, search_range=50, steps=3, snap=True, preset=z_pos) # snap at top but return center z\n",
    "                        if bg_flag:\n",
    "                            if len(support_points)>=2:\n",
    "                                core.set_position(pos_z)\n",
    "                            else:\n",
    "                                pos_z = z_pos\n",
    "                            core.wait_for_device(z_device)\n",
    "                            pixels = snap_image(core, rgb=True, flip_channel=True)\n",
    "                        else:\n",
    "                            pos_z, pixels, _ = autofocus(config, core, mag='20x', rgb=True, search_range=10, steps=3, snap=True, check_background=False) # snap at top but return center z\n",
    "                            support_points.append((x_pos, y_pos))\n",
    "                            support_focus.append(pos_z)\n",
    "                    z_positions[pos] = pos_z \n",
    "                    \n",
    "                pixels = img_as_float(pixels)   \n",
    "                \n",
    "                if estimate_background:\n",
    "                    if focus_dive:\n",
    "                        bg_flag = bg_flag\n",
    "                    else:\n",
    "                        bg_flag = is_background(pixels, t=0.35, tt=0.35)\n",
    "                        print('hard check')\n",
    "                    if bg_flag:\n",
    "                        print(' (background tile)')\n",
    "                        redive_flag=True\n",
    "                        bg_stack.append(pixels)\n",
    "                    else:\n",
    "                        redive_flag=False                \n",
    "                if background_image is not None and not estimate_background:\n",
    "                    pixels = white_balance(config, pixels, background_image)\n",
    "                    pixels = flat_field(pixels, bg_img)\n",
    "                    \n",
    "                show.set_data(pixels)\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "                io.imsave(acq_path+'/{}-{}.tiff'.format(pos, bg_flag), img_as_ubyte(pixels))\n",
    "                tile_count = tile_count + 1\n",
    "                sys.stdout.write('\\r {}/{} tiles done'.format(tile_count, position_list.shape[0]))\n",
    "            \n",
    "        if position_list.shape[1] == 2:\n",
    "            tile_count = 0\n",
    "            core.set_focus_device(config[\"focus-device\"])\n",
    "            z_positions=np.ones(position_list.shape[0]) * core.get_position()\n",
    "            autofocus_count = 0\n",
    "            for pos in range(position_list.shape[0]):\n",
    "                x_pos = position_list[pos, 0]\n",
    "                y_pos = position_list[pos, 1]\n",
    "                \n",
    "                x_pos, y_pos = limit_stage(config, (x_pos, y_pos)) #, (config[\"hard-limit-x\"][0], config[\"hard-limit-x\"][1]))\n",
    "                    \n",
    "                xy_device = core.get_xy_stage_device()\n",
    "                z_device = core.get_focus_device()\n",
    "                core.set_xy_position(x_pos, y_pos)\n",
    "                core.wait_for_device(xy_device)\n",
    "                \n",
    "                    \n",
    "                if focus_dive and mag=='4x':\n",
    "                    support_distance = config[\"pixel-size-bf-4x\"] * config[\"camera-resolution\"][1] * config[\"autofocus-speed\"]\n",
    "                    idx, min_distance = distance((x_pos, y_pos), support_points)\n",
    "                    if min_distance <= support_distance:\n",
    "                        pos_z = support_focus[idx]\n",
    "                        pos_z = limit_stage(config, (pos_z,), (config[\"Z-stage-4x\"],))\n",
    "                        core.set_position(pos_z)\n",
    "                        core.wait_for_device(z_device)\n",
    "                        pixels = snap_image(core, rgb=True, flip_channel=True)\n",
    "                        bg_flag = is_background(pixels, t=0.35, tt=0.35)\n",
    "                    else:\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='4x', rgb=True, search_range=100, steps=3, snap=True) # snap at top but return center z\n",
    "                        if not bg_flag:\n",
    "                            support_points.append((x_pos, y_pos))\n",
    "                            support_focus.append(pos_z)\n",
    "                    z_positions[pos] = pos_z\n",
    "                    \n",
    "                if focus_dive and mag=='20x':\n",
    "                    support_distance = config[\"pixel-size-bf-20x\"] * config[\"camera-resolution\"][1] * config[\"autofocus-speed\"]\n",
    "                    idx, min_distance = distance((x_pos, y_pos), support_points)\n",
    "                    if min_distance <= support_distance:\n",
    "                        pos_z = support_focus[idx]\n",
    "                        pos_z = limit_stage(config, (pos_z,), (config[\"Z-stage-20x\"],))\n",
    "                        core.set_position(pos_z)\n",
    "                        core.wait_for_device(z_device)\n",
    "                        pixels = snap_image(core, rgb=True, flip_channel=True)\n",
    "                        bg_flag = is_background(pixels, t=0.35, tt=0.35)\n",
    "                    else:\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='20x', rgb=True, search_range=50, steps=3, snap=False) # snap at top but return center z\n",
    "                        pos_z, pixels, bg_flag = autofocus(config, core, mag='20x', rgb=True, search_range=10, steps=3, snap=True) # snap at top but return center z\n",
    "                        if not bg_flag:\n",
    "                            support_points.append((x_pos, y_pos))\n",
    "                            support_focus.append(pos_z)\n",
    "                    z_positions[pos] = pos_z    \n",
    "                    \n",
    "                pixels = img_as_float(pixels)                   \n",
    "                \n",
    "                if estimate_background:\n",
    "                    if focus_dive:\n",
    "                        bg_flag = bg_flag\n",
    "                    else:\n",
    "                        bg_flag = is_background(pixels, t=0.35, tt=0.35)\n",
    "                        print('hard check')\n",
    "                    if bg_flag:\n",
    "                        print(' (background tile)')\n",
    "                        redive_flag=True\n",
    "                        bg_stack.append(pixels)\n",
    "                    else:\n",
    "                        redive_flag=False                \n",
    "                if background_image is not None and not estimate_background:\n",
    "                    pixels = white_balance(config, pixels, background_image)\n",
    "                    pixels = flat_field(pixels, bg_img)\n",
    "                    \n",
    "                show.set_data(pixels)\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "                io.imsave(acq_path+'/{}-{}.tiff'.format(pos, bg_flag), img_as_ubyte(pixels))\n",
    "                tile_count = tile_count + 1\n",
    "                sys.stdout.write('\\r {}/{} tiles done'.format(tile_count, position_list.shape[0]))\n",
    "        returns = []\n",
    "        if estimate_background:\n",
    "            if len(bg_stack)==0:\n",
    "                returns.append(background_image)\n",
    "                io.imsave(acq_path+'/bg_img.tiff', img_as_ubyte(background_image))\n",
    "            else:\n",
    "                bg_stack= np.stack(bg_stack)\n",
    "                median = np.median(bg_stack, axis=0)\n",
    "                median = img_as_float(median)\n",
    "                returns.append(median)\n",
    "                io.imsave(acq_path+'/bg_img.tiff', img_as_ubyte(median))\n",
    "        if focus_dive:\n",
    "            z_positions = z_positions.reshape(position_list.shape[0], 1)\n",
    "            returns.append(z_positions)\n",
    "        return tuple(returns)\n",
    "\n",
    "def autofocus(config, core, method='edge', mag='4x', interpolation='quadratic', rgb=True, search_range=45, steps=3, snap=True, crop_ratio=1.0, flip_channel=True, check_background=True, offset=0, preset=None):\n",
    "    if mag=='4x':\n",
    "        drift_origin = config[\"Z-stage-4x\"]\n",
    "    if mag=='20x':\n",
    "        drift_origin = config[\"Z-stage-20x\"]\n",
    "    core.set_focus_device(config[\"focus-device\"])   \n",
    "    current_z = core.get_position()\n",
    "    interval_z = search_range/steps\n",
    "    scores = []\n",
    "    positions = []\n",
    "    count = 0\n",
    "    for step in range(-int(np.floor(steps/2)), int(np.ceil(steps/2))):\n",
    "        position_z = step * interval_z + current_z\n",
    "        position_z = limit_stage(config, (position_z,), (drift_origin,))\n",
    "        core.set_position(position_z)\n",
    "        core.wait_for_system()\n",
    "        count = count + 1\n",
    "        pixels = snap_image(core, rgb=rgb, flip_channel=True)\n",
    "        if check_background and step==-int(np.floor(steps/2)):\n",
    "            bg_flag = is_background(pixels, t=0.35, tt=0.35)\n",
    "            if bg_flag:\n",
    "                if preset is not None:\n",
    "                    preset = limit_stage(config, (preset,), (drift_origin,))\n",
    "                    core.set_position(preset)\n",
    "                else:\n",
    "                    drift_origin = limit_stage(config, (drift_origin,), (drift_origin,))\n",
    "                    core.set_position(drift_origin)\n",
    "                core.wait_for_system()\n",
    "                print(\"Is background\")\n",
    "                return drift_origin, pixels, bg_flag # TODO: return center z instead of top\n",
    "        img_gray = color.rgb2gray(pixels)\n",
    "        sys.stdout.write(\"\\r Diving focus at \" + str(step))\n",
    "        if method == 'entropy':\n",
    "            score = shannon_entropy(img_gray)\n",
    "        if method == 'edge':\n",
    "            score = np.mean(sobel(img_gray))\n",
    "        scores.append(score)\n",
    "        positions.append(position_z)\n",
    "        print('Score: {}, Position {}'.format(score, position_z))\n",
    "    scores_array = np.asarray(scores)\n",
    "    positions_array = np.asarray(positions) \n",
    "    new_length = len(positions) * 100\n",
    "    new_x = np.linspace(positions_array.min(), positions_array.max(), new_length)\n",
    "    new_y = sp.interpolate.interp1d(positions_array, scores_array, kind=interpolation)(new_x)\n",
    "    idx = np.argmax(new_y)\n",
    "    focus_z = new_x[idx]\n",
    "    focus_z = limit_stage(config, (focus_z,), (position_z,))\n",
    "    if np.abs(focus_z-drift_origin) > 200:\n",
    "        print(\"Large change in z-stage , reset focus\")\n",
    "        focus_z = drift_origin\n",
    "        core.set_position(drift_origin)\n",
    "        core.wait_for_system()\n",
    "    else:\n",
    "        core.set_position(focus_z)\n",
    "        core.wait_for_system()\n",
    "    if snap:\n",
    "        pixels = snap_image(core, rgb=rgb, flip_channel=True)\n",
    "        return focus_z+offset, pixels, False\n",
    "    else:\n",
    "        return focus_z+offset, None, False   \n",
    "\n",
    "print(\"System configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_stage(config, args=None, default=None):\n",
    "    if len(args)==1:\n",
    "        if default[0] < config[\"hard-limit-z\"][0] or default[0] > config[\"hard-limit-z\"][1]:\n",
    "            raise SystemExit(\"Default z out of range\")\n",
    "        if args[0] < config[\"hard-limit-z\"][0] or args[0] > config[\"hard-limit-z\"][1]:\n",
    "            print(\"Warning: z-stage out of range {}\".format(args))\n",
    "            if len(default)==1:\n",
    "                return default[0]\n",
    "            else:\n",
    "                raise SystemExit(\"Stop acquisition\")\n",
    "        else:\n",
    "            return args[0]\n",
    "    if len(args)==2:\n",
    "        if args[0] < config[\"hard-limit-x\"][0] or args[0] > config[\"hard-limit-x\"][1] or args[1] < config[\"hard-limit-y\"][0] or args[1] > config[\"hard-limit-y\"][1]:\n",
    "            print(\"Warning: xy-stage out of range x: {} y: {}\".format(args[0], args[1]))\n",
    "            if len(default)==2:\n",
    "                return default\n",
    "            else:\n",
    "                raise SystemExit(\"Stop acquisition\")\n",
    "                return None\n",
    "        else:\n",
    "            return args\n",
    "    if len(args)==3:\n",
    "        if args[0] < config[\"hard-limit-x\"][0] or args[0] > config[\"hard-limit-x\"][1] or args[1] < config[\"hard-limit-y\"][0] or args[1] > config[\"hard-limit-y\"][1] or args[2] < config[\"hard-limit-z\"][0] or args[2] > config[\"hard-limit-z\"][1]:\n",
    "            print(\"Warning: stage out of range x: {} y: {} z: {}\".format(args[0], args[1], args[2]))\n",
    "            if len(default)==3:\n",
    "                return default\n",
    "            else:\n",
    "                raise SystemExit(\"Stop acquisition\")\n",
    "                return None\n",
    "        else:\n",
    "            return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Acquisition hardware configuration\n",
    "Edit user configuration. After editing, click blank space in front of the section and hit Shift+Return, or click the \"run the selected cells and advance\" botton in the top menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_config = {\n",
    "    \n",
    "    ### User configuration ###\n",
    "    \n",
    "    # Quick configuration group for LSM\n",
    "    \"exposure-level\" : 'high',\n",
    "    # 'low'     -> scan rate: '500000.0000', pockel cell gain: 0.3, PMT gain: 0.35\n",
    "    # 'mid'     -> scan rate: '400000.0000', pockel cell gain: 0.4, PMT gain: 0.4\n",
    "    # 'high'    -> scan rate: '250000.0000', pockel cell gain: 0.425, PMT gain: 0.425\n",
    "    # 'extreme' -> scan rate: '200000.0000', pockel cell gain: 0.45, PMT gain: 0.45\n",
    "    \n",
    "    \"snr-level\" : 'low',\n",
    "    # Estimiated correction according to sample SNR level. Available value: 'low', 'mid', 'high'\n",
    "    \n",
    "    \"autofocus-speed\" : 6,\n",
    "    # Speed of software autofocus, integer: 1~5. Bigger value leads to faster brightfield scan but potentially lower autofocus performance\n",
    "       \n",
    "    \"lsm-resolution\" : 256, \n",
    "    # LSM scan resolution, available resolution: 256, 512, 1024\n",
    "    \n",
    "    \"lsm-bin-factor\" : 4,\n",
    "    # LSM scan pixel average factor, positive integer\n",
    "    \n",
    "    \"lsm-scan-rate\" : '400000.0000', \n",
    "    # LSM scan rate, available value (string): '125000.0000', '200000.0000', '250000.0000','400000.0000', '500000.0000', '625000.0000', '1000000.0000'\n",
    "    \n",
    "    \"lsm-pc-power\" : 0.4, \n",
    "    # LSM pockel cell gain, float point value: 0.0 ~ 1.0\n",
    "    \n",
    "    \"lsm-pmt-gain\" : 0.4,\n",
    "    # LSM PMT gain, float point value: 0.0 ~ 1.0\n",
    "    \n",
    "    \"slide-box\" : (-100, 600, 25500.0, 17000.0), \n",
    "    # Pre-define scan area (read out values from the stage): (start x stage position, start y stage position, end x stage position, end y stage position)\n",
    "    \n",
    "    \"enhancement-type\" : None,\n",
    "    # Runtime enhancement method, available value (string or None): 'Self', 'Supervised', None\n",
    "    \n",
    "     \"classifier\" : None,\n",
    "    # Automatic target detection model, available value (string or None): 'MIL', 'Supervised', None \n",
    "    \n",
    "    \"classifier-backbone\" : \"ResNet18\",\n",
    "    # Backbone for CNN model, available value (string): 'ResNet18', 'ResNet34' \n",
    "    \n",
    "    \"classifier-num-class\" : 2,\n",
    "    # Number of class for the detector, non-zero integer\n",
    "    \n",
    "    \"mil-classifier-thresh\" : 2,\n",
    "    # Threshold for MIL classifier. Obtained from training.\n",
    "    \n",
    "    \"slide-type\" : \"TMA\",\n",
    "    # Type of image the inference is applied, available value (string): \"TMA\", \"slide\"\n",
    "    \n",
    "    \"gpu\" : False,\n",
    "    # Is GPU available? Available value (boolean): True, False       \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate acquisition configuration\n",
    "Run the below section. Wait for message containing the configuration specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration specs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exposure-level': 'high',\n",
       " 'snr-level': 'low',\n",
       " 'autofocus-speed': 6,\n",
       " 'lsm-resolution': 256,\n",
       " 'lsm-bin-factor': 4,\n",
       " 'lsm-scan-rate': '250000.0000',\n",
       " 'lsm-pc-power': 0.425,\n",
       " 'lsm-pmt-gain': 0.425,\n",
       " 'slide-box': (-100, 600, 25500.0, 17000.0),\n",
       " 'enhancement-type': None,\n",
       " 'classifier': None,\n",
       " 'classifier-backbone': 'ResNet18',\n",
       " 'classifier-num-class': 2,\n",
       " 'mil-classifier-thresh': 2,\n",
       " 'slide-type': 'TMA',\n",
       " 'gpu': False,\n",
       " 'pixel-size-bf-20x': 0.222,\n",
       " 'pixel-size-bf-4x': 1.105,\n",
       " 'pixel-size-shg-base': 0.509,\n",
       " 'pixel-size-shg': 0.509,\n",
       " 'camera-resolution': (1392, 1040),\n",
       " 'lsm-resolution-base': (512, 512),\n",
       " 'slide-size': (40000.0, 20000.0),\n",
       " 'Z-stage-20x': -6980,\n",
       " 'Z-stage-laser': -6640,\n",
       " 'Z-stage-4x': 3570,\n",
       " 'F-stage-20x': -15800,\n",
       " 'F-stage-laser': -18500,\n",
       " 'F-stage-4x': -1000,\n",
       " 'Z-bf-offset': -10500,\n",
       " 'hard-limit-z': (-7700.0, 17000.0),\n",
       " 'hard-limit-x': (-3000.0, 40000.0),\n",
       " 'hard-limit-y': (-2200, 19000.0),\n",
       " 'hard-limit-f': (-19000, 0),\n",
       " '20x-bf-offset': (-600, 10),\n",
       " 'shg-offset': (-580, -280),\n",
       " 'led-4x': 4,\n",
       " 'led-20x': 5,\n",
       " 'focus-device': 'ZStage:Z:32',\n",
       " 'condensor-device': 'ZStage:F:32',\n",
       " 'led-device': ('LED-Dev1ao0', 'Voltage'),\n",
       " 'obj-device': ('Turret:O:35', 'Label')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### right general save range check function\n",
    "hard_config = {\n",
    "    ### Hard configuration, \n",
    "    \"pixel-size-bf-20x\" : 0.222, # 0.222 micron/pixel at (1392, 1040)\n",
    "    \"pixel-size-bf-4x\" : 1.105, # 1.305 micron/pixel at (1392, 1040)\n",
    "    \"pixel-size-shg-base\" : 0.509, # 0.509 micron/pixel at 256\n",
    "    \"pixel-size-shg\" : 0.509,\n",
    "    \"camera-resolution\" : (1392, 1040), # (width, height)\n",
    "    \"lsm-resolution-base\" : (512, 512),\n",
    "    \"slide-size\" : (40000.0, 20000.0), # (width, height) (70000, -20000)\n",
    "#     \"Z-stage-20x\" : -6930, # -6930 + 290 / 10500\n",
    "    \"Z-stage-20x\" : -6980, # -6930 + 290 / 10500\n",
    "    \"Z-stage-laser\" : -6640, #-6640 \n",
    "    \"Z-stage-4x\" : 3570, # -2300\n",
    "    \"F-stage-20x\" : -15800, # 11000\n",
    "    \"F-stage-laser\" : -18500, # -17500\n",
    "    \"F-stage-4x\" : -1000,\n",
    "    \"Z-bf-offset\" : -10500,\n",
    "    \"hard-limit-z\" : (-7700.0, 17000.0),\n",
    "    \"hard-limit-x\" : (-3000.0, 40000.0),\n",
    "    \"hard-limit-y\" : (-2200, 19000.0),\n",
    "    \"hard-limit-f\" : (-19000, 0),\n",
    "    \"20x-bf-offset\" : (-600, 10), # 4x + this value to 20x // (-590, 74)\n",
    "    \"shg-offset\" : (-580, -280), # 4x + this value to shg // (-580, -172)\n",
    "    \"led-4x\" : 4,\n",
    "    \"led-20x\" : 5,\n",
    "    \"focus-device\" : 'ZStage:Z:32',\n",
    "    \"condensor-device\" : 'ZStage:F:32',\n",
    "    \"led-device\" : ('LED-Dev1ao0', 'Voltage'),\n",
    "    \"obj-device\" : ('Turret:O:35', 'Label'),\n",
    "}\n",
    "config = {**user_config, **hard_config}\n",
    "config = config_sys(config)\n",
    "print(\"Configuration specs:\")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Pycro-Manager and PyImageJ\n",
    "Make sure Micro-Manager and OpenScan is running appropriately. Run the below section. Wait for message \"Succeeded!\". Run only once, unless the notebook or Micro-Manager had restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ij = imagej.init('fiji\\\\fiji\\\\Fiji.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure acquistion parameters\n",
    "Enter values and run the below section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path = 'data/acquisition'\n",
    "# Data save path, relative path by default\n",
    "\n",
    "acq_name = 'PA-961e-A2-20210804' # do not include space\n",
    "# Acquisition name\n",
    "\n",
    "# user_config[\"slide-box\"] = (-3000, -500, 32500, 17000)\n",
    "user_config[\"slide-box\"] = (3000, 0, 6000, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acq_name_4x = acq_name + '-4x-bf'\n",
    "config = {**user_config, **hard_config}\n",
    "config = config_sys(config)\n",
    "position_list = generate_grid(config, mag='4x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-fffed2fef5b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdefault_bg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'acquisition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macq_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"*\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bg_img.tiff\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstitching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mij\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macq_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macq_name_4x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mposition_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflip_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorrection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_image\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_bg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#stitching(config, ij, save_path=save_path, acq_name=acq_name_4x, mda=False, position_list=position_list.reshape(position_list.shape[0]*position_list.shape[1], -1), flip_y=True, correction=True, background_image=bg_image)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mexport_slide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'4x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r, 4x brighfield acquisition done!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "default_bg = io.imread(glob.glob(os.path.join('data', 'acquisition', acq_name+\"*\", \"bg_img.tiff\"))[-1])\n",
    "stitching(config, ij, save_path=save_path, acq_name=acq_name_4x, mda=False, position_list=position_list.reshape(position_list.shape[0]*position_list.shape[1], -1), flip_y=True, correction=True, background_image=default_bg)\n",
    "#stitching(config, ij, save_path=save_path, acq_name=acq_name_4x, mda=False, position_list=position_list.reshape(position_list.shape[0]*position_list.shape[1], -1), flip_y=True, correction=True, background_image=bg_image)\n",
    "export_slide(mag='4x')\n",
    "print('\\r, 4x brighfield acquisition done!')\n",
    "Audio('C:/Windows/Media/Windows Proximity Notification.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Close imagej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ij.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ij = imagej.init('fiji\\\\fiji\\\\Fiji.app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
